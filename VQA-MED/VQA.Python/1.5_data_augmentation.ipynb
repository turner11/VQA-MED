{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook will will generate more data to train on based on given train and validation sets.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some main functions we used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from common.functions import get_highlighted_function_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The augmentation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">.highlight .hll { background-color: #ffffcc }\n",
       ".highlight  { background: #f8f8f8; }\n",
       ".highlight .c { color: #408080; font-style: italic } /* Comment */\n",
       ".highlight .err { border: 1px solid #FF0000 } /* Error */\n",
       ".highlight .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".highlight .o { color: #666666 } /* Operator */\n",
       ".highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
       ".highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
       ".highlight .cp { color: #BC7A00 } /* Comment.Preproc */\n",
       ".highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
       ".highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
       ".highlight .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
       ".highlight .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".highlight .ge { font-style: italic } /* Generic.Emph */\n",
       ".highlight .gr { color: #FF0000 } /* Generic.Error */\n",
       ".highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".highlight .gi { color: #00A000 } /* Generic.Inserted */\n",
       ".highlight .go { color: #888888 } /* Generic.Output */\n",
       ".highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".highlight .gs { font-weight: bold } /* Generic.Strong */\n",
       ".highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".highlight .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".highlight .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".highlight .kt { color: #B00040 } /* Keyword.Type */\n",
       ".highlight .m { color: #666666 } /* Literal.Number */\n",
       ".highlight .s { color: #BA2121 } /* Literal.String */\n",
       ".highlight .na { color: #7D9029 } /* Name.Attribute */\n",
       ".highlight .nb { color: #008000 } /* Name.Builtin */\n",
       ".highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".highlight .no { color: #880000 } /* Name.Constant */\n",
       ".highlight .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
       ".highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
       ".highlight .nf { color: #0000FF } /* Name.Function */\n",
       ".highlight .nl { color: #A0A000 } /* Name.Label */\n",
       ".highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".highlight .nv { color: #19177C } /* Name.Variable */\n",
       ".highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".highlight .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".highlight .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".highlight .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".highlight .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".highlight .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".highlight .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".highlight .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".highlight .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".highlight .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".highlight .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
       ".highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
       ".highlight .sx { color: #008000 } /* Literal.String.Other */\n",
       ".highlight .sr { color: #BB6688 } /* Literal.String.Regex */\n",
       ".highlight .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".highlight .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".highlight .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".highlight .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".highlight .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".highlight .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".highlight .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".highlight .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">generate_image_augmentations</span><span class=\"p\">(</span><span class=\"n\">image_path</span><span class=\"p\">,</span>\n",
       "                                 <span class=\"n\">output_dir</span><span class=\"p\">,</span>\n",
       "                                 <span class=\"n\">rotation_range</span><span class=\"o\">=</span><span class=\"mi\">25</span><span class=\"p\">,</span>  <span class=\"c1\"># Units: degrees</span>\n",
       "                                 <span class=\"n\">width_shift_range</span><span class=\"o\">=</span><span class=\"mf\">0.15</span><span class=\"p\">,</span>\n",
       "                                 <span class=\"n\">height_shift_range</span><span class=\"o\">=</span><span class=\"mf\">0.15</span><span class=\"p\">,</span>\n",
       "                                 <span class=\"n\">shear_range</span><span class=\"o\">=</span><span class=\"mf\">0.</span><span class=\"p\">,</span>  <span class=\"c1\"># Units: degrees</span>\n",
       "                                 <span class=\"n\">zoom_range</span><span class=\"o\">=</span><span class=\"mf\">0.15</span><span class=\"p\">,</span>\n",
       "                                 <span class=\"n\">fill_mode</span><span class=\"o\">=</span><span class=\"s1\">&#39;nearest&#39;</span><span class=\"p\">,</span>\n",
       "                                 <span class=\"n\">augmentation_count</span><span class=\"o\">=</span><span class=\"mi\">20</span><span class=\"p\">):</span>\n",
       "    <span class=\"kn\">from</span> <span class=\"nn\">keras.preprocessing.image</span> <span class=\"kn\">import</span> <span class=\"n\">ImageDataGenerator</span><span class=\"p\">,</span> <span class=\"n\">img_to_array</span><span class=\"p\">,</span> <span class=\"n\">load_img</span>  <span class=\"c1\"># ,array_to_img</span>\n",
       "\n",
       "    <span class=\"n\">datagen</span> <span class=\"o\">=</span> <span class=\"n\">ImageDataGenerator</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">rotation_range</span><span class=\"o\">=</span><span class=\"n\">rotation_range</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">width_shift_range</span><span class=\"o\">=</span><span class=\"n\">width_shift_range</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">height_shift_range</span><span class=\"o\">=</span><span class=\"n\">height_shift_range</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">shear_range</span><span class=\"o\">=</span><span class=\"n\">shear_range</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">zoom_range</span><span class=\"o\">=</span><span class=\"n\">zoom_range</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">horizontal_flip</span><span class=\"o\">=</span><span class=\"bp\">False</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">vertical_flip</span><span class=\"o\">=</span><span class=\"bp\">False</span><span class=\"p\">,</span>\n",
       "        <span class=\"n\">fill_mode</span><span class=\"o\">=</span><span class=\"n\">fill_mode</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"n\">img</span> <span class=\"o\">=</span> <span class=\"n\">load_img</span><span class=\"p\">(</span><span class=\"n\">image_path</span><span class=\"p\">)</span>  <span class=\"c1\"># this is a PIL image</span>\n",
       "    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">img_to_array</span><span class=\"p\">(</span><span class=\"n\">img</span><span class=\"p\">)</span>  <span class=\"c1\"># this is a Numpy array with shape (3, X, Y)</span>\n",
       "    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,)</span> <span class=\"o\">+</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">)</span>  <span class=\"c1\"># this is a Numpy array with shape (1, 3, X, Y)</span>\n",
       "\n",
       "    <span class=\"c1\"># the .flow() command below generates batches of randomly transformed images</span>\n",
       "    <span class=\"c1\"># and saves the results to the `preview/` directory</span>\n",
       "    <span class=\"n\">ext</span> <span class=\"o\">=</span> <span class=\"n\">image_path</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s1\">&#39;.&#39;</span><span class=\"p\">)[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n",
       "    <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n",
       "    <span class=\"k\">for</span> <span class=\"n\">_</span> <span class=\"ow\">in</span> <span class=\"n\">datagen</span><span class=\"o\">.</span><span class=\"n\">flow</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">save_to_dir</span><span class=\"o\">=</span><span class=\"n\">output_dir</span><span class=\"p\">,</span> <span class=\"n\">save_format</span><span class=\"o\">=</span><span class=\"n\">ext</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">i</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n",
       "        <span class=\"k\">if</span> <span class=\"n\">i</span> <span class=\"o\">&gt;=</span> <span class=\"n\">augmentation_count</span><span class=\"p\">:</span>\n",
       "            <span class=\"k\">break</span>  <span class=\"c1\"># otherwise the generator would loop indefinitely</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from common.functions import generate_image_augmentations\n",
    "code = get_highlighted_function_code(generate_image_augmentations,remove_comments=False)\n",
    "IPython.display.display(code)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## The code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import IPython\n",
    "from IPython.display import Image, display\n",
    "from tqdm import tqdm\n",
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "import logging\n",
    "from collections import defaultdict, namedtuple\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.utils import VerboseTimer\n",
    "from common.functions import get_highlighted_function_code, generate_image_augmentations,  get_image\n",
    "from common.os_utils import File\n",
    "from common.settings import data_access\n",
    "import vqa_logger \n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-09-20 14:03:04][data_access.api][DEBUG] loading processed data from:\n",
      "C:\\Users\\avitu\\Documents\\GitHub\\VQA-MED\\VQA-MED\\VQA.Python\\data\\model_input.parquet\n",
      "[2021-09-20 14:03:04][data_access.api][DEBUG] loading parquet from:\n",
      "C:\\Users\\avitu\\Documents\\GitHub\\VQA-MED\\VQA-MED\\VQA.Python\\data\\model_input.parquet\n",
      "[2021-09-20 14:03:04][common.utils][DEBUG] Starting 'Loading parquet'\n",
      "[2021-09-20 14:03:04][common.utils][DEBUG] Loading parquet: 0:00:00.029002\n",
      "[2021-09-20 14:03:04][common.utils][DEBUG] Starting 'Converting to pandas'\n",
      "[2021-09-20 14:03:04][common.utils][DEBUG] Converting to pandas: 0:00:00.015486\n"
     ]
    }
   ],
   "source": [
    "df_data = data_access.load_processed_data(columns=['path','question','answer', 'group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 14792\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>what kind of image is this?</td>\n",
       "      <td>cta - ct angiography</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>is this a t1 weighted image?</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path  \\\n",
       "500  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "501  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "\n",
       "                         question                answer  group  \n",
       "500   what kind of image is this?  cta - ct angiography  train  \n",
       "501  is this a t1 weighted image?                    no  train  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df_data[df_data.group.isin(['train','validation'])]\n",
    "print(f'Data length: {len(df_data)}')        \n",
    "df_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500           train\n",
       "13292    validation\n",
       "Name: group, dtype: category\n",
       "Categories (3, object): [test, train, validation]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.group.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the augmaentation we will use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n",
      "Generating augmentations for 0 images\n"
     ]
    }
   ],
   "source": [
    "df_train = df_data[df_data.group == 'train']\n",
    "\n",
    "image_paths = df_train.path.drop_duplicates()\n",
    "print(len(image_paths))\n",
    "\n",
    "ImageInfo = namedtuple('ImageInfo',\n",
    "                       ['original_path', 'file_name', 'extension', 'target_location', 'out_put_folder_exists'])\n",
    "\n",
    "\n",
    "def get_file_info(fn):\n",
    "    image_folder, full_file_name = os.path.split(fn)\n",
    "    file_name, ext = full_file_name.split('.')[-2:]\n",
    "    output_dir = os.path.join(image_folder, 'augmentations', full_file_name + '\\\\')\n",
    "    output_exists = os.path.isdir(output_dir)\n",
    "    return ImageInfo(fn, file_name, ext, output_dir, output_exists)\n",
    "\n",
    "\n",
    "images_info = [get_file_info(p) for p in image_paths]\n",
    "df_all_images_info = pd.DataFrame(images_info)\n",
    "df_images_info = df_all_images_info[~df_all_images_info.out_put_folder_exists]\n",
    "\n",
    "print(f'Generating augmentations for {len(df_images_info)} images')\n",
    "\n",
    "\n",
    "def augments_single_image(row_index):\n",
    "    try:\n",
    "        row = df_images_info.iloc[row_index]\n",
    "        msg = (f'Augmenting ({row_index + 1}/{len(df_images_info)})\\t\"{row.file_name}\" -> {row.target_location}')\n",
    "        if row_index % 100 == 0:\n",
    "            print(msg)\n",
    "        File.validate_dir_exists(row.target_location)\n",
    "        generate_image_augmentations(row.original_path, row.target_location)\n",
    "        res = 1\n",
    "    except Exception as e:\n",
    "        msg = str(e)\n",
    "        res = 0\n",
    "    return (res, msg)\n",
    "\n",
    "\n",
    "# for tpl_data in non_existing_paths:\n",
    "# augments_single_image(tpl_data)\n",
    "pool = Pool(processes=8)\n",
    "inputs = range(len(df_images_info))\n",
    "pool_res = pool.map(augments_single_image, inputs)\n",
    "pool.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success: 0\n",
      "\n",
      "failes: 0\n"
     ]
    }
   ],
   "source": [
    "failes = [tpl[1] for tpl in pool_res if tpl[0]==0]\n",
    "successes = [tpl[1] for tpl in pool_res if tpl[0]==1]\n",
    "\n",
    "\n",
    "f_summary = '\\n'.join(failes[:5])\n",
    "s_summary = '\\n'.join(successes[:5])\n",
    "summary = f'success: {len(successes)}\\n{s_summary}\\nfailes: {len(failes)}\\n{f_summary}'.strip()\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_path</th>\n",
       "      <th>file_name</th>\n",
       "      <th>extension</th>\n",
       "      <th>target_location</th>\n",
       "      <th>out_put_folder_exists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>synpic41148</td>\n",
       "      <td>jpg</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>synpic43984</td>\n",
       "      <td>jpg</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>synpic38930</td>\n",
       "      <td>jpg</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>synpic52143</td>\n",
       "      <td>jpg</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>synpic20934</td>\n",
       "      <td>jpg</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_path    file_name extension  \\\n",
       "0  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...  synpic41148       jpg   \n",
       "1  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...  synpic43984       jpg   \n",
       "2  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...  synpic38930       jpg   \n",
       "3  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...  synpic52143       jpg   \n",
       "4  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...  synpic20934       jpg   \n",
       "\n",
       "                                     target_location  out_put_folder_exists  \n",
       "0  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...                   True  \n",
       "1  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...                   True  \n",
       "2  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...                   True  \n",
       "3  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...                   True  \n",
       "4  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...                   True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_images_info.head()\n",
    "# len(df_all_images_info.original_path.drop_duplicates()), len(df_all_images_info), len(df_all_images_info.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n",
      "[2021-09-20 14:03:06][common.utils][DEBUG] Starting 'Collecting augmented rows'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3200/3200 [00:07<00:00, 451.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-09-20 14:03:13][common.utils][DEBUG] Collecting augmented rows: 0:00:07.110168\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the original path\n",
    "df_augments = df_train[['path']].drop_duplicates().copy()\n",
    "df_augments['augmentation'] = 0\n",
    "df_augments['original_path'] = df_augments.path\n",
    "\n",
    "print(len(df_augments))\n",
    "\n",
    "# Add the augmentations\n",
    "new_rows = []\n",
    "AugmentationRow = namedtuple('AugmentationRow',['original_path', 'path', 'augmentation'])\n",
    "index = df_all_images_info[['original_path','target_location']].set_index('original_path')\n",
    "with VerboseTimer(\"Collecting augmented rows\"):\n",
    "    pbar = tqdm(df_augments.iterrows(), total=len(df_augments))\n",
    "    for i, row in pbar:\n",
    "        augment_location = Path(index.loc[row.original_path].target_location)\n",
    "        assert augment_location.exists()\n",
    "        augment_files = sorted(augment_location.iterdir())\n",
    "\n",
    "        curr_augmentations = [AugmentationRow(row.original_path, path=str(augmented_file),augmentation=i)\n",
    "                              for i, augmented_file\n",
    "                              in enumerate(augment_files, start=1)] # 0 is for the original\n",
    "        new_rows.extend(curr_augmentations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last preperatons (sorting, data types...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_augments.append(new_rows)\n",
    "df['augmentation'] = df.augmentation.astype(int)\n",
    "df = df.sort_values(['augmentation'], ascending=[True])\n",
    "# print(len(df), len(df.drop_duplicates()))\n",
    "assert len(df) ==  len(df.drop_duplicates()), 'got duplicated row'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lets take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>augmentation</th>\n",
       "      <th>original_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>0</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>0</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19699</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>20</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63925</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>20</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path  augmentation  \\\n",
       "500    C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...             0   \n",
       "2627   C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...             0   \n",
       "19699  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...            20   \n",
       "63925  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...            20   \n",
       "\n",
       "                                           original_path  \n",
       "500    C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...  \n",
       "2627   C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...  \n",
       "19699  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...  \n",
       "63925  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[0,1,-2,-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-09-20 14:03:13][data_access.api][DEBUG] Saving augmentations:\n",
      "C:\\Users\\avitu\\Documents\\GitHub\\VQA-MED\\VQA-MED\\VQA.Python\\data\\augmentations.parquet\n",
      "[2021-09-20 14:03:13][common.utils][DEBUG] Starting 'Saving augmentations'\n",
      "[2021-09-20 14:03:14][common.utils][DEBUG] Saving augmentations: 0:00:00.484151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\avitu\\\\Documents\\\\GitHub\\\\VQA-MED\\\\VQA-MED\\\\VQA.Python\\\\data\\\\augmentations.parquet'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_access.save_augmentation_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-09-20 14:03:14][data_access.api][DEBUG] Loading augmentations:\n",
      "C:\\Users\\avitu\\Documents\\GitHub\\VQA-MED\\VQA-MED\\VQA.Python\\data\\augmentations.parquet\n",
      "[2021-09-20 14:03:14][data_access.api][DEBUG] loading parquet from:\n",
      "C:\\Users\\avitu\\Documents\\GitHub\\VQA-MED\\VQA-MED\\VQA.Python\\data\\augmentations.parquet\n",
      "[2021-09-20 14:03:14][common.utils][DEBUG] Starting 'Loading parquet'\n",
      "[2021-09-20 14:03:14][common.utils][DEBUG] Loading parquet: 0:00:00.002993\n",
      "[2021-09-20 14:03:14][common.utils][DEBUG] Starting 'Converting to pandas'\n",
      "[2021-09-20 14:03:14][common.utils][DEBUG] Converting to pandas: 0:00:00.006216\n",
      "[2021-09-20 14:03:14][data_access.api][DEBUG] Loading augmentations:\n",
      "C:\\Users\\avitu\\Documents\\GitHub\\VQA-MED\\VQA-MED\\VQA.Python\\data\\augmentations.parquet\n",
      "[2021-09-20 14:03:14][data_access.api][DEBUG] loading parquet from:\n",
      "C:\\Users\\avitu\\Documents\\GitHub\\VQA-MED\\VQA-MED\\VQA.Python\\data\\augmentations.parquet\n",
      "[2021-09-20 14:03:14][common.utils][DEBUG] Starting 'Loading parquet'\n",
      "[2021-09-20 14:03:14][common.utils][DEBUG] Loading parquet: 0:00:00.026002\n",
      "[2021-09-20 14:03:14][common.utils][DEBUG] Starting 'Converting to pandas'\n",
      "[2021-09-20 14:03:14][common.utils][DEBUG] Converting to pandas: 0:00:00.016902\n",
      "[2021-09-20 14:03:14][data_access.api][DEBUG] Loading augmentations:\n",
      "C:\\Users\\avitu\\Documents\\GitHub\\VQA-MED\\VQA-MED\\VQA.Python\\data\\augmentations.parquet\n",
      "[2021-09-20 14:03:14][data_access.api][DEBUG] loading parquet from:\n",
      "C:\\Users\\avitu\\Documents\\GitHub\\VQA-MED\\VQA-MED\\VQA.Python\\data\\augmentations.parquet\n",
      "[2021-09-20 14:03:14][common.utils][DEBUG] Starting 'Loading parquet'\n",
      "[2021-09-20 14:03:14][common.utils][DEBUG] Loading parquet: 0:00:00.084624\n",
      "[2021-09-20 14:03:14][common.utils][DEBUG] Starting 'Converting to pandas'\n",
      "[2021-09-20 14:03:14][common.utils][DEBUG] Converting to pandas: 0:00:00.024846\n",
      "67126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>original_path</th>\n",
       "      <th>augmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42801</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3876</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21149</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63816</th>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path  \\\n",
       "42801  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "3876   C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "2005   C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "21149  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "63816  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...   \n",
       "\n",
       "                                           original_path augmentation  \n",
       "42801  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...            5  \n",
       "3876   C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...            1  \n",
       "2005   C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...            8  \n",
       "21149  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...           11  \n",
       "63816  C:\\Users\\Public\\Documents\\Data\\2019\\train\\Trai...           11  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmentation_1 = data_access.load_augmentation_data(augmentations=1)\n",
    "augmentation_5 = data_access.load_augmentation_data(augmentations=5)\n",
    "augmentation_all = data_access.load_augmentation_data()\n",
    "print(len(augmentation_all))\n",
    "augmentation_all.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n"
     ]
    }
   ],
   "source": [
    "orig_a1 = set(augmentation_1.original_path)\n",
    "orig_a5 = set(augmentation_5.original_path)\n",
    "\n",
    "diff = orig_a1 ^ orig_a5\n",
    "diff\n",
    "print(len(orig_a1))\n",
    "assert len(diff) == 0, 'Expected all augmentations to have all orignal paths'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
